## instad of using an xutom ai  model, you can use an prebuilt llm model like llama3.2, or groq for fater inference, but he advantage of using this is that it gives faster response cpomapred to the llm model,

# but the disadvantage is that it is not as accurate as the llm model, so you can use this for simple tasks like answering questions
##try using an groq model by taking the api keyy or any hugging face or nvidia nim models also 